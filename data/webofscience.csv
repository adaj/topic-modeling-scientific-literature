Publication Type,Authors,Book Authors,Book Editors,Book Group Authors,Author Full Names,Book Author Full Names,Group Authors,Article Title,Source Title,Book Series Title,Book Series Subtitle,Language,Document Type,Conference Title,Conference Date,Conference Location,Conference Sponsor,Conference Host,Author Keywords,Keywords Plus,Abstract,Addresses,Reprint Addresses,Email Addresses,Researcher Ids,ORCIDs,Funding Orgs,Funding Text,Cited References,Cited Reference Count,"Times Cited, WoS Core","Times Cited, All Databases",180 Day Usage Count,Since 2013 Usage Count,Publisher,Publisher City,Publisher Address,ISSN,eISSN,ISBN,Journal Abbreviation,Journal ISO Abbreviation,Publication Date,Publication Year,Volume,Issue,Part Number,Supplement,Special Issue,Meeting Abstract,Start Page,End Page,Article Number,DOI,Book DOI,Early Access Date,Number of Pages,WoS Categories,Research Areas,IDS Number,UT (Unique WOS ID),Pubmed Id,Open Access Designations,Highly Cited Status,Hot Paper Status,Date of Export
J,"Nizzoli, L; Tardelli, S; Avvenuti, M; Cresci, S; Tesconi, M; Ferrara, E",,,,"Nizzoli, Leonardo; Tardelli, Serena; Avvenuti, Marco; Cresci, Stefano; Tesconi, Maurizio; Ferrara, Emilio",,,Charting the Landscape of Online Cryptocurrency Manipulation,IEEE ACCESS,,,,,,,,,,,,"Cryptocurrencies represent one of the most attractive markets for financial speculation. As a consequence, they have attracted unprecedented attention on social media. Besides genuine discussions and legitimate investment initiatives, several deceptive activities have flourished. In this work, we chart the online cryptocurrency landscape across multiple platforms. To reach our goal, we collected a large dataset, composed of more than 50M messages published by almost 7M users on Twitter, Telegram and Discord, over three months. We performed bot detection on Twitter accounts sharing invite links to Telegram and Discord channels, and we discovered that more than 56% of them were bots or suspended accounts. Then, we applied topic modeling techniques to Telegram and Discord messages, unveiling two different deception schemes - pump-and-dump'' and Ponzi'' - and identifying the channels involved in these frauds. Whereas on Discord we found a negligible level of deception, on Telegram we retrieved 296 channels involved in pump-and-dump and 432 involved in Ponzi schemes, accounting for a striking 20% of the total. Moreover, we observed that 93% of the invite links shared by Twitter bots point to Telegram pump-and-dump channels, shedding light on a little-known social bot activity. Charting the landscape of online cryptocurrency manipulation can inform actionable policies to fight such abuse.",,,,"Nizzoli, Leonardo/ABE-5096-2020; Cresci, Stefano/Q-4031-2018; Ferrara, Emilio/F-6136-2012; TESCONI, MAURIZIO/P-2441-2016","Nizzoli, Leonardo/0000-0002-9168-8992; Cresci, Stefano/0000-0003-0170-2445; Ferrara, Emilio/0000-0002-1942-2831; TESCONI, MAURIZIO/0000-0001-8228-7807",,,,,,,,,,,,2169-3536,,,,,,2020,8,,,,,,113230,113245,,10.1109/ACCESS.2020.3003370,,,,,,,WOS:000546416100018,,,,,
J,"Tardelli, S; Avvenuti, M; Tesconi, M; Cresci, S",,,,"Tardelli, Serena; Avvenuti, Marco; Tesconi, Maurizio; Cresci, Stefano",,,Detecting inorganic financial campaigns on Twitter,INFORMATION SYSTEMS,,,,,,,,,,,,"Online financial content is widespread on social media, especially on Twitter. The possibility to access open, real-time data about stock market information and firms' public reputation can bring competitive advantages to industry insiders. However, as many studies extensively demonstrated before, manipulative campaigns by social bots do not spare the financial sector either. In this work, we show that the more viral a stock is on Twitter, the more that virality is artificially caused by social bots. This result is also confirmed when considering accounts suspended by Twitter instead of bots. Starting from this finding, we then propose two methods for detecting the presence and the extent of financial disinformation on Twitter, via classification and regression. Our systems exploit hundreds of features to encode the characteristics of viral discussions, including features about: participating users, textual content of shared posts, temporal patterns of diffusion, and financial information about stocks. We experiment with different combinations of algorithms and features, achieving excellent results for the detection of financial disinformation (F 1 = 0.97) and promising results for the challenging task of estimating the extent of inorganic activity within financial discussions (R-2 = 0.81, MAE = 4.9%). Our compelling results pave the way for the deployment of novel systems for protecting against financial disinformation. (c) 2021 Elsevier Ltd. All rights reserved.",,,,"; Cresci, Stefano/Q-4031-2018","Tardelli, Serena/0000-0002-7235-7055; Cresci, Stefano/0000-0003-0170-2445",,,,,,,,,,,,0306-4379,1873-6076,,,,JAN,2022,103,,,,,,,,101769,10.1016/j.is.2021.101769,,,,,,,WOS:000705021600011,,,,,
J,"Khaund, T; Kirdemir, B; Agarwal, N; Liu, H; Morstatter, F",,,,"Khaund, Tuja; Kirdemir, Baris; Agarwal, Nitin; Liu, Huan; Morstatter, Fred",,,Social Bots and Their Coordination During Online Campaigns: A Survey,IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS,,,,,,,,,,,,"Online social networks (OSNs) are a major component of societal digitalization. OSNs alter how people communicate, make decisions, and form or change their beliefs, attitudes, and behaviors. Thus, they can now impact social groups, financial systems, and political communication at scale. As one type of OSN, social media platforms, such as Facebook, Twitter, and YouTube, serve as outlets for users to convey information to an audience as broad or targeted as the user desires. Over the years, these social media platforms have been infected with automated accounts, or bots, that are capable of hijacking conversations, influencing other users, and manipulating content dissemination. Although benign bots exist to facilitate legitimate activities, we focus on bots designed to perform malicious acts through social media platforms. Bots that mimic the social behaviors of humans are referred to as social bots. Social bots help automate sociotechnical behaviors, such as ``liking'' tweets, tweeting/retweeting a message, following users, and coordinating with or even competing against other bots. Some advanced social bots exhibit highly sophisticated traits of coordination and communication with complex organizational structures. This article presents a detailed survey of social bots, their types and behaviors, and how they impact social media, identification algorithms, and their coordination strategies in OSNs. The survey also discusses coordination in areas such as biological systems, interorganizational networks, and coordination games. Existing research extensively studied bot detection, but bot coordination is still emerging and requires more in-depth analysis. The survey covers existing techniques and open research issues on the analysis of social bots, their behaviors, and how social network theories can be leveraged to assess coordination during online campaigns.",,,,,,,,,,,,,,,,,2329-924X,,,,,,,,,,,,,,,,10.1109/TCSS.2021.3103515,,AUG 2021,,,,,WOS:000732378800001,,,,,
J,"Mirtaheri, M; Abu-El-Haija, S; Morstatter, F; Steeg, GV; Galstyan, A",,,,"Mirtaheri, Mehrnoosh; Abu-El-Haija, Sami; Morstatter, Fred; Steeg, Greg Ver; Galstyan, Aram",,,Identifying and Analyzing Cryptocurrency Manipulations in Social Media,IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS,,,,,,,,,,,,"Interest surrounding cryptocurrencies, digital or virtual currencies that are used as a medium for financial transactions, has grown tremendously in the recent years. The anonymity surrounding these currencies makes investors particularly susceptible to fraudity-such as pump and dump scams-where the goal is to artificially inflate the perceived worth of a currency, luring victims into investing before the fraudsters can sell their holdings. Because of the speed and relative anonymity offered by social platforms such as Twitter and Telegram, social media has become a preferred platform for scammers who wish to spread false hype about the cryptocurrency they are trying to pump. In this work, we propose and evaluate a computational approach that can automatically identify pump and dump scams as they unfold by combining information across social media platforms. We also develop a multi-modal approach for predicting whether a particular pump attempt will succeed or not. Finally, we analyze the prevalence of bots in cryptocurrency related tweets, and observe a significant increase in bot activity during the pump attempts.",,,,,,,,,,,,,,,,,2329-924X,,,,,JUN,2021,8,3,,,,,607,617,,10.1109/TCSS.2021.3059286,,,,,,,WOS:000655822700008,,,,,
J,"Sela, A; Milo, O; Kagan, E; Ben-Gal, I",,,,"Sela, Alon; Milo, Orit; Kagan, Eugene; Ben-Gal, Irad",,,Improving information spread by spreading groups,ONLINE INFORMATION REVIEW,,,,,,,,,,,,"Purpose The purpose of this paper is to propose a novel method to enhance the spread of messages in social networks by Spreading Groups. These sub-structures of highly connected accounts intentionally echo messages between the members of the subgroup at the early stages of a spread. This echoing further boosts the spread to regions substantially larger than the initial region. These spreading accounts can be actual humans or social bots. Design/methodology/approach The paper reveals an interesting anomaly in information cascades in Twitter and proposes the spreading group model that explains this anomaly. The model was tested using an agent-based simulation, real Twitter data and questionnaires. Findings The messages of few anonymous Twitter accounts spread on average more than well-known global financial media groups, such as The Wall Street Journal or Bloomberg. The spreading groups (also sometimes called BotNets) model provides an effective mechanism that can explain these findings. Social implications With the blossoming of fake news, one might tend to assess the reliability of news by the number of users involved in its spread. This heuristic might be easily fooled by spreading groups. Furthermore, spreading groups consisting of a blend of human and computerized bots might be hard to detect. They can be used to manipulate financial markets or political campaigns. Originality/value The paper demonstrates an anomaly in Twitter that was not studied before. It proposes a novel approach to spreading messages in social networks. The methods presented in the paper are valuable for anyone interested in spreading messages or an agenda such as political actors or other agenda enthusiasts. While social bots have been widely studied, their synchronization to increase the spread is novel.",,,,"Sela, Alon/ABF-9451-2020","Sela, Alon/0000-0001-5544-0837",,,,,,,,,,,,1468-4527,1468-4535,,,,NOV 15,2019,44,1,,,,,24,42,,10.1108/OIR-08-2018-0245,,NOV 2019,,,,,WOS:000501748600001,,,,,
S,"Land, MK; Aronson, JD",,"MacCoun, RJ",,"Land, Molly K.; Aronson, Jay D.",,,Human Rights and Technology: New Challenges for Justice and Accountability,"ANNUAL REVIEW OF LAW AND SOCIAL SCIENCE, VOL 16",Annual Review of Law and Social Science,,,,,,,,,,,"This review surveys contemporary challenges in the field of technology and human rights. The increased use of artificial intelligence (AI) in decision making in the public and private sectors-e.g., in criminal justice, employment, public service, and financial contexts-poses significant threats to human rights. AI obscures and attenuates responsibility for harms in ways that undermine traditional mechanisms for holding wrongdoers accountable. Further, technologies that scholars and practitioners once thought would democratize human rights fact finding have been weaponized by state and non-state actors. They are now used to surveil and track citizens and spread disinformation that undermines public trust in knowledge. Addressing these challenges requires efforts to ensure that the development and implementation of new technologies respects and promotes human rights. Traditional distinctions between public and private must be updated to remain relevant in the face of deeply enmeshed state and corporate action in connection with technological innovation.",,,,,,,,,,,,,,,,,1550-3585,,978-0-8243-4116-9,,,,2020,16,,,,,,223,240,,10.1146/annurev-lawsocsci-060220-081955,,,,,,,WOS:000590408800013,,,,,
J,"Varol, O; Ferrara, E; Menczer, F; Flammini, A",,,,"Varol, Onur; Ferrara, Emilio; Menczer, Filippo; Flammini, Alessandro",,,Early detection of promoted campaigns on social media,EPJ DATA SCIENCE,,,,,,,,,,,,"Social media expose millions of users every day to information campaigns - some emerging organically from grassroots activity, others sustained by advertising or other coordinated efforts. These campaigns contribute to the shaping of collective opinions. While most information campaigns are benign, some may be deployed for nefarious purposes, including terrorist propaganda, political astroturf, and financial market manipulation. It is therefore important to be able to detect whether a meme is being artificially promoted at the very moment it becomes wildly popular. This problem has important social implications and poses numerous technical challenges. As a first step, here we focus on discriminating between trending memes that are either organic or promoted by means of advertisement. The classification is not trivial: ads cause bursts of attention that can be easily mistaken for those of organic trends. We designed a machine learning framework to classify memes that have been labeled as trending on Twitter. After trending, we can rely on a large volume of activity data. Early detection, occurring immediately at trending time, is a more challenging problem due to the minimal volume of activity data that is available prior to trending. Our supervised learning framework exploits hundreds of time- varying features to capture changing network and diffusion patterns, content and sentiment information, timing signals, and user meta-data. We explore different methods for encoding feature time series. Using millions of tweets containing trending hashtags, we achieve 75% AUC score for early detection, increasing to above 95% after trending. We evaluate the robustness of the algorithms by introducing random temporal shifts on the trend time series. Feature selection analysis reveals that content cues provide consistently useful signals; user features are more informative for early detection, while network and timing features are more helpful once more data is available.",,,,"Varol, Onur/T-6764-2019; Ferrara, Emilio/F-6136-2012","Varol, Onur/0000-0002-3994-6106; Ferrara, Emilio/0000-0002-1942-2831",,,,,,,,,,,,,2193-1127,,,,JUL 5,2017,6,,,,,,,,13,10.1140/epjds/s13688-017-0111-y,,,,,,,WOS:000405396400001,,,,,
